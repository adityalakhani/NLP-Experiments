{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3529cbb4-bd0d-4a30-b4e6-172079b8e959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "29/29 [==============================] - 7s 182ms/step - loss: 6.0805 - accuracy: 0.0596\n",
      "Epoch 2/30\n",
      "29/29 [==============================] - 5s 188ms/step - loss: 5.5963 - accuracy: 0.0579\n",
      "Epoch 3/30\n",
      "29/29 [==============================] - 5s 188ms/step - loss: 5.2977 - accuracy: 0.0850\n",
      "Epoch 4/30\n",
      "29/29 [==============================] - 5s 181ms/step - loss: 4.9914 - accuracy: 0.1010\n",
      "Epoch 5/30\n",
      "29/29 [==============================] - 5s 183ms/step - loss: 4.5903 - accuracy: 0.1501\n",
      "Epoch 6/30\n",
      "29/29 [==============================] - 6s 216ms/step - loss: 4.1638 - accuracy: 0.1932\n",
      "Epoch 7/30\n",
      "29/29 [==============================] - 6s 213ms/step - loss: 3.6979 - accuracy: 0.2517\n",
      "Epoch 8/30\n",
      "29/29 [==============================] - 6s 190ms/step - loss: 3.2641 - accuracy: 0.3068\n",
      "Epoch 9/30\n",
      "29/29 [==============================] - 5s 189ms/step - loss: 2.8370 - accuracy: 0.3593\n",
      "Epoch 10/30\n",
      "29/29 [==============================] - 6s 191ms/step - loss: 2.4533 - accuracy: 0.4299\n",
      "Epoch 11/30\n",
      "29/29 [==============================] - 6s 191ms/step - loss: 2.0987 - accuracy: 0.5105\n",
      "Epoch 12/30\n",
      "29/29 [==============================] - 6s 200ms/step - loss: 1.7820 - accuracy: 0.5872\n",
      "Epoch 13/30\n",
      "29/29 [==============================] - 6s 204ms/step - loss: 1.5014 - accuracy: 0.6672\n",
      "Epoch 14/30\n",
      "29/29 [==============================] - 6s 199ms/step - loss: 1.2696 - accuracy: 0.7241\n",
      "Epoch 15/30\n",
      "29/29 [==============================] - 6s 199ms/step - loss: 1.0785 - accuracy: 0.7478\n",
      "Epoch 16/30\n",
      "29/29 [==============================] - 6s 203ms/step - loss: 0.9340 - accuracy: 0.7942\n",
      "Epoch 17/30\n",
      "29/29 [==============================] - 5s 184ms/step - loss: 0.8001 - accuracy: 0.8206\n",
      "Epoch 18/30\n",
      "29/29 [==============================] - 5s 171ms/step - loss: 0.6970 - accuracy: 0.8394\n",
      "Epoch 19/30\n",
      "29/29 [==============================] - 5s 175ms/step - loss: 0.6191 - accuracy: 0.8620\n",
      "Epoch 20/30\n",
      "29/29 [==============================] - 5s 173ms/step - loss: 0.5373 - accuracy: 0.8863\n",
      "Epoch 21/30\n",
      "29/29 [==============================] - 5s 172ms/step - loss: 0.4830 - accuracy: 0.9018\n",
      "Epoch 22/30\n",
      "29/29 [==============================] - 5s 188ms/step - loss: 0.4310 - accuracy: 0.9145\n",
      "Epoch 23/30\n",
      "29/29 [==============================] - 6s 206ms/step - loss: 0.3844 - accuracy: 0.9200\n",
      "Epoch 24/30\n",
      "29/29 [==============================] - 5s 178ms/step - loss: 0.3392 - accuracy: 0.9299\n",
      "Epoch 25/30\n",
      "29/29 [==============================] - 5s 189ms/step - loss: 0.3061 - accuracy: 0.9415\n",
      "Epoch 26/30\n",
      "29/29 [==============================] - 5s 167ms/step - loss: 0.2789 - accuracy: 0.9448\n",
      "Epoch 27/30\n",
      "29/29 [==============================] - 5s 168ms/step - loss: 0.2476 - accuracy: 0.9531\n",
      "Epoch 28/30\n",
      "29/29 [==============================] - 5s 183ms/step - loss: 0.2185 - accuracy: 0.9581\n",
      "Epoch 29/30\n",
      "29/29 [==============================] - 5s 165ms/step - loss: 0.1993 - accuracy: 0.9680\n",
      "Epoch 30/30\n",
      "29/29 [==============================] - 5s 169ms/step - loss: 0.1840 - accuracy: 0.9746\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "\n",
    "with open('test.txt', 'r', encoding='utf-8') as file:\n",
    "    corpus = file.read()\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([corpus])\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "input_sequences = []\n",
    "for line in corpus.split('\\n'):\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "max_sequence_length = max([len(seq) for seq in input_sequences])\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')\n",
    "\n",
    "X = input_sequences[:, :-1]\n",
    "y = input_sequences[:, -1]\n",
    "\n",
    "embedding_dim = 64\n",
    "lstm_units = 64\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(total_words, embedding_dim, input_length=max_sequence_length-1),\n",
    "    LSTM(lstm_units),\n",
    "    Dense(total_words, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X, y, epochs=30, verbose=1, batch_size=64)\n",
    "\n",
    "model.save('text_generation_lstm_model_v2.h5')\n",
    "with open('tokenizer_v2.pickle', 'wb') as tokenizer_file:\n",
    "    pickle.dump(tokenizer, tokenizer_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cae7933a-d29f-4026-92f4-76fc1ace7194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as the sun gently nudged awoke it's captives in the hall quickly rushed over to pay their respects\n"
     ]
    }
   ],
   "source": [
    "model = load_model('text_generation_lstm_model_v2.h5')\n",
    "with open('tokenizer_v2.pickle', 'rb') as tokenizer_file:\n",
    "    tokenizer = pickle.load(tokenizer_file)\n",
    "\n",
    "def generate_text(seed_text, next_words, tokenizer, max_sequence_length, model):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_length - 1, padding='pre')\n",
    "        predicted = model.predict(token_list, verbose=0)\n",
    "        predicted_word_index = np.argmax(predicted)\n",
    "        predicted_word = tokenizer.index_word[predicted_word_index]\n",
    "\n",
    "        seed_text += \" \" + predicted_word\n",
    "\n",
    "    return seed_text\n",
    "\n",
    "seed_text = \"as the sun gently nudged awoke it's captives\"\n",
    "next_words = 10\n",
    "\n",
    "# Generate text\n",
    "generated_text = generate_text(seed_text, next_words, tokenizer, max_sequence_length, model)\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef09097b-fdfd-470d-bb3a-edc1a596b961",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
