{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0c11015-64c2-42f8-b9f6-67f73583f517",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Aditya\n",
      "[nltk_data]     lakhani\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Aditya\n",
      "[nltk_data]     lakhani\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9654e1c3-38e0-46d5-8461-12bc289f0f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    preprocessed_sentences = []\n",
    "    for sentence in sentences:\n",
    "        words = word_tokenize(sentence.lower())\n",
    "        filtered_words = [word for word in words if word not in stop_words]\n",
    "        preprocessed_sentences.append(filtered_words)\n",
    "    return preprocessed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ee7dd49-e886-420e-98c4-5e842d32ecb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity(sentence1, sentence2):\n",
    "    words1 = set(sentence1)\n",
    "    words2 = set(sentence2)\n",
    "    if len(words1) == 0 or len(words2) == 0:\n",
    "        return 0\n",
    "    return len(words1.intersection(words2)) / (np.log(len(words1)) + np.log(len(words2)))\n",
    "\n",
    "def build_similarity_matrix(sentences):\n",
    "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    "    for i in range(len(sentences)):\n",
    "        for j in range(len(sentences)):\n",
    "            if i != j:\n",
    "                similarity_matrix[i][j] = sentence_similarity(sentences[i], sentences[j])\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da56ea6e-1949-45fd-92e4-d36fbe06c180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagerank(similarity_matrix, damping=0.85, max_iterations=100, tolerance=0.0001):\n",
    "    scores = np.ones(len(similarity_matrix))\n",
    "    for _ in range(max_iterations):\n",
    "        new_scores = (1 - damping) + damping * np.dot(similarity_matrix.T, scores)\n",
    "        if np.linalg.norm(scores - new_scores) < tolerance:\n",
    "            break\n",
    "        scores = new_scores\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e2a63d8-3d7b-49a5-8048-7e5b8d0272af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thus, Huang Xiaolong was led by Su Yan and Huang Peng to the Martial Hall of the Huang Clan Manor. This old man was none other Huang Xiaolong’s grandfather, Huang Qide, the Huang Clan Manor’s lord for the past forty years, the very person who established the Huang Clan. Huang Ming, Huang Peng and Su Yan also moved forward quickly: \"Dad!” \n",
      " Huang Xiaolong and Huang Wei both came forward: \"Grandpa.” \n",
      " Huang Qide smiled, then nodded his head at Huang Ming’s group before turning to face the rest of Huang Clan Manor’s people-- he smiled and said: \"Do not stand on ceremony.\n"
     ]
    }
   ],
   "source": [
    "def generate_summary(text, num_sentences=3):\n",
    "    preprocessed_sentences = preprocess(text)\n",
    "    similarity_matrix = build_similarity_matrix(preprocessed_sentences)\n",
    "    scores = pagerank(similarity_matrix)\n",
    "    ranked_sentences = sorted(((scores[i], i) for i in range(len(scores))), reverse=True)\n",
    "    top_sentences_indices = [i for _, i in ranked_sentences[:num_sentences]]\n",
    "    top_sentences_indices.sort()\n",
    "    summary = ' '.join([sent_tokenize(text)[i] for i in top_sentences_indices])\n",
    "    return summary\n",
    "\n",
    "# Example usage:\n",
    "file = open(\"test.txt\", \"r\", encoding = \"utf8\")\n",
    "text = file.read()\n",
    "\n",
    "summary = generate_summary(text)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c39d3f9-527f-4b03-96fc-9801b56755b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
